{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CART\n",
      "Accuracy: 0.93\n",
      "Precision: 0.93\n",
      "Recall: 0.93\n",
      "F1 Score: 0.93\n",
      "Confusion Matrix:\n",
      "[[39  4]\n",
      " [ 4 67]]\n",
      "\n",
      "\n",
      "Model: ID3\n",
      "Accuracy: 0.95\n",
      "Precision: 0.95\n",
      "Recall: 0.95\n",
      "F1 Score: 0.95\n",
      "Confusion Matrix:\n",
      "[[39  4]\n",
      " [ 2 69]]\n",
      "\n",
      "\n",
      "Model: C4.5 (Gini)\n",
      "Accuracy: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 0.94\n",
      "F1 Score: 0.94\n",
      "Confusion Matrix:\n",
      "[[39  4]\n",
      " [ 3 68]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Implement CART (Classification and Regression Trees)\n",
    "class Node:\n",
    "    def __init__(self, depth, max_depth):\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = None\n",
    "\n",
    "class CART:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_impurity=1e-7):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity = min_impurity\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        node = Node(depth, self.max_depth)\n",
    "\n",
    "        if (len(unique_classes) == 1) or (depth == self.max_depth) or (n_samples < self.min_samples_split):\n",
    "            node.value = unique_classes[np.argmax(class_counts)]\n",
    "            return node\n",
    "\n",
    "        best_gini = 1.0\n",
    "        for feature_index in range(n_features):\n",
    "            unique_values = np.unique(X[:, feature_index])\n",
    "            for threshold in unique_values:\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = X[:, feature_index] > threshold\n",
    "                if len(y[left_mask]) > 0 and len(y[right_mask]) > 0:\n",
    "                    gini_left = self._gini_impurity(y[left_mask])\n",
    "                    gini_right = self._gini_impurity(y[right_mask])\n",
    "                    gini = (len(y[left_mask]) / n_samples) * gini_left + (len(y[right_mask]) / n_samples) * gini_right\n",
    "                    if gini < best_gini:\n",
    "                        best_gini = gini\n",
    "                        node.feature_index = feature_index\n",
    "                        node.threshold = threshold\n",
    "                        left_mask_best = left_mask\n",
    "                        right_mask_best = right_mask\n",
    "\n",
    "        if best_gini < self.min_impurity:\n",
    "            node.value = unique_classes[np.argmax(class_counts)]\n",
    "            return node\n",
    "\n",
    "        node.left = self._build_tree(X[left_mask_best, :], y[left_mask_best], depth + 1)\n",
    "        node.right = self._build_tree(X[right_mask_best, :], y[right_mask_best], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        n_samples = len(y)\n",
    "        if n_samples == 0:\n",
    "            return 0.0\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        p = class_counts / n_samples\n",
    "        return 1 - np.sum(p ** 2)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict_tree(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_tree(self, x, node=None):\n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_tree(x, node.left)\n",
    "        else:\n",
    "            return self._predict_tree(x, node.right)\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_breast_cancer()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate CART\n",
    "cart = CART(max_depth=5)\n",
    "cart.fit(X_train, y_train)\n",
    "y_pred_cart = cart.predict(X_test)\n",
    "\n",
    "# Implement ID3 using scikit-learn\n",
    "id3 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "id3.fit(X_train, y_train)\n",
    "y_pred_id3 = id3.predict(X_test)\n",
    "\n",
    "# Implement C4.5 (using Gini index) using scikit-learn\n",
    "c45 = DecisionTreeClassifier(criterion=\"gini\", max_depth=5)\n",
    "c45.fit(X_train, y_train)\n",
    "y_pred_c45 = c45.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "def evaluate_model(model_name, y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"\\n\")\n",
    "\n",
    "evaluate_model(\"CART\", y_test, y_pred_cart)\n",
    "evaluate_model(\"ID3\", y_test, y_pred_id3)\n",
    "evaluate_model(\"C4.5 (Gini)\", y_test, y_pred_c45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "\n",
    "*1-Data Loading and Splitting:*\n",
    "\n",
    "-The code loads the Breast Cancer dataset using scikit-learn's load_breast_cancer.\n",
    "-It splits the dataset into training and testing sets using train_test_split.\n",
    "\n",
    "*2-Decision Tree Implementations:*\n",
    "\n",
    "-The code implements a custom CART (Classification and Regression Trees) classifier, including a Node class and a CART class, following the Gini impurity for node splitting.\n",
    "-It also implements decision trees using scikit-learn for both ID3 (entropy criterion) and C4.5 (Gini criterion) algorithms.\n",
    "\n",
    "*3-Model Training:*\n",
    "\n",
    "-The code trains each of the three decision tree models (CART, ID3, and C4.5) on the training data.\n",
    "\n",
    "*4-Model Evaluation:*\n",
    "\n",
    "The code defines an evaluate_model function to calculate various evaluation metrics for each model, including accuracy, precision, recall, F1-score, and the confusion matrix.\n",
    "It applies this function to the testing data for each model.\n",
    "\n",
    "*5-Results and Interpretation:*\n",
    "-Results\n",
    "\n",
    "-CART:The CART model achieved an accuracy of 93%, indicating that it correctly predicted the class labels for 93% of the test samples. The precision, recall, and F1 score are also approximately 93%, suggesting that the model provides a good balance between precision and recall. The confusion matrix shows that there were 39 true negatives, 67 true positives, 4 false positives, and 4 false negatives.\n",
    "\n",
    "-ID3:The ID3 model achieved a higher accuracy of 95% compared to CART. It also has higher precision, recall, and F1 score. The confusion matrix shows that there were 39 true negatives, 69 true positives, 4 false positives, and 2 false negatives.\n",
    "\n",
    "-C4.5:The C4.5 model achieved an accuracy of 94% and demonstrated good precision, recall, and F1 score. The confusion matrix indicates that there were 39 true negatives, 68 true positives, 4 false positives, and 3 false negatives.\n",
    "\n",
    "-Interpretation\n",
    "\n",
    "-Based on the results provided, the best model among CART, ID3, and C4.5 for the Breast Cancer classification task is ID3. It achieved the highest accuracy of 95%, making it the top-performing model in terms of overall classification accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
